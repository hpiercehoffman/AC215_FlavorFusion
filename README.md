AC215: Milestone 3
==============================

Project Organization
------------
      ├── LICENSE
      ├── README.md
      ├── notebooks
      ├── references
      ├── reports
      │   └── milestone2.md
      ├── requirements.txt
      └── src
            ├── docker-volumes
            │   ├── google-data.dvc
            │   ├── lsars-data.dvc
            │   └── notebooks
            │       ├── process_google.ipynb
            │       ├── process_lsars.ipynb
            │       └── Evaluation_Example.ipynb
            ├── preprocess_google
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess.py
            │   ├── cors.py
            │   ├── utils.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh	
            ├── preprocess_lsars
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess_lsars.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh
            └── train
                ├── Dockerfile
                ├── Pipfile
                ├── Pipfile.lock
                ├── train.py
                ├── docker-compose.yml
                └── docker-shell.sh

--------
# Milestone 3 Overview

**Team Members**   
Varun Ullanat, Hannah Pierce-Hoffman

**Group Name**   
FlavorFusion

**Project**   
In this project, we aim to build an app that captures cultural differences in Google resturaunt reviews using abstractive summaries generated by a large language model<sup>1</sup>. 

## Milestone 3 Contents ##

The focus of this milestone is model training. For information on data preprocessing, see our [Milestone 2 report](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone2.md).

### train ###
This container trains the [PRIMERA model](https://github.com/allenai/PRIMER) on the [LSARS dataset](https://github.com/ScarletPan/LSARS). We use 5,000 preprocessed and translated data points which we generated for Milestone 2. Each data point contains **10-40 product reviews** and **one summary** which captures information from all of the reviews.




### docker-volumes ###
This directory is mounted to both the `preprocess_google` and `preprocess_lsars` Docker containers in the `docker-compose.yml` file for each container. This directory contains data (not tracked on Github) as well as notebooks which may be edited inside the Docker container.

### Notebooks ###    
This directory is currently empty, but will be used to store code which doesn't belong to a specific container, such as reports, insights, or visualizations.

### References ###  
This directory is currently empty, but will be used to store code from the [PRIMERA model](https://github.com/allenai/PRIMER).

--------
# Setup Notes #

### Running Docker containers ###   
Both Docker containers delivered in this milestone can be run via the `docker-shell.sh` script inside the container. To run the container of your choice, do the following:
- Clone the repository and checkout the `milestone2` branch
- `cd src/<desired_directory>`
- `chmod 777 docker-shell.sh`
- `./docker-shell.sh`
The relevant Dockerfile will build and you will be dropped into a shell prompt as `app` user. From there, you can run a data processing script or connect to a Jupyter session. 

### Running preprocess_lsars.py script ###
To run this script, you must activate the `preprocess_lsars` docker container. Once you are inside the container, you can run the script with the following arguments:
- `-d` or `--download`: Flag to indicate that the untranslated data should be downloaded from our GCS bucket (will not overwrite any previously translated data)
- `--reviews_file_path`: Path to untranslated review file (either pre-mounted or downloaded with the `-d` flag)
- `--start_line`: Line in the input file where translation should start (each line is a single JSON record containing a summary and a group of reviews)
- `--stop_line`: Line in the input file where translation should stop
- `--output_file_path`: Path where translated data will be placed (should be in a mounted volume to avoid losing the data)
- `--upload`: Flag to indicate whether the output file should be uploaded to our GCS bucket 
   
Since the LSARS dataset contains large files, we provide `start_line` and `stop_line` arguments so the user can avoid reading an entire file into memory at once. We also provide the option of downloading the raw data, which is useful if the user is working in a GCP VM without a mounted bucket.     
    
Translating 500 reviews takes about 6 minutes. The script will output a progress bar showing how many records have been translated.



### Committing data files to DVC ###
We use DVC as our data versioning pipeline. Our DVC configuration has one remote for each dataset. The remote for LSARS data is called `lsars-data`, and the remote for Google data is called `google-data`. 

To download a specific version of one of our datasets, you can use the [dvc get](https://dvc.org/doc/command-reference/get) command. You need to specify a [dataset tag](https://github.com/hpiercehoffman/AC215_FlavorFusion/tags) as well as a remote to use.

**Example of downloading a specific dataset version**   
`dvc get https://github.com/hpiercehoffman/AC215_FlavorFusion/ src/docker-volumes/lsars-data --force --rev  lsars_train500 --remote lsars-data`     
  
The above command will download the `lsars-data` directory from the `lsars-data` remote. The data version will match the `lsars_train500` tag.

To add new or modified data files to DVC, you can use the [dvc add](https://dvc.org/doc/command-reference/add) command. You can then use [dvc push](https://dvc.org/doc/command-reference/push) to push to the appropriate remote.   
  
**Example of pushing new data to DVC**    
`dvc add src/docker-volumes/lsars-data`  
`dvc push src/docker-volumes/lsars-data -r lsars-data`  
  
The above commands will add any modifications in the `lsars-data` directory to the DVC staging area, then push these modifications to the DVC remote which handles LSARS data.

# References #

1. Xiao, Wen, Iz Beltagy, Giuseppe Carenini, and Arman Cohan. “PRIMERA: Pyramid-Based Masked Sentence Pre-Training for Multi-Document Summarization.” arXiv, March 16, 2022. http://arxiv.org/abs/2110.08499.
2. Yan, An, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. “Personalized Showcases: Generating Multi-Modal Explanations for Recommendations.” arXiv, April 6, 2023. http://arxiv.org/abs/2207.00422.
3. Pan, Haojie, Rongqin Yang, Xin Zhou, Rui Wang, Deng Cai, and Xiaozhong Liu. “Large Scale Abstractive Multi-Review Summarization (LSARS) via Aspect Alignment.” In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2337–46. Virtual Event China: ACM, 2020. https://doi.org/10.1145/3397271.3401439.
4. Text generated by ChatGPT, OpenAI, March 7, 2023, https://chat.openai.com/chat.



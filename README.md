AC215: Milestone 3
==============================

Project Organization
------------
      ├── LICENSE
      ├── README.md
      ├── notebooks
      ├── references
      ├── reports
      │   └── milestone2.md
      ├── requirements.txt
      └── src
            ├── docker-volumes
            │   ├── google-data.dvc
            │   ├── lsars-data.dvc
            │   └── notebooks
            │       ├── process_google.ipynb
            │       ├── process_lsars.ipynb
            │       └── Evaluation_Example.ipynb
            ├── preprocess_google
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess.py
            │   ├── cors.py
            │   ├── utils.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh	
            ├── preprocess_lsars
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess_lsars.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh
            └── train
                ├── Dockerfile
                ├── Pipfile
                ├── Pipfile.lock
                ├── train.py
                ├── docker-compose.yml
                └── docker-shell.sh

--------
# Milestone 3 Overview

**Team Members**   
Varun Ullanat, Hannah Pierce-Hoffman

**Group Name**   
FlavorFusion

**Project**   
In this project, we aim to build an app that captures cultural differences in Google resturaunt reviews using abstractive summaries generated by a large language model<sup>1</sup>. 

## Milestone 3 Contents ##

The focus of this milestone is model training. For information on data preprocessing, see our [Milestone 2 report](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone2.md). Data preprocessing takes place in the **preprocess_google** and **preprocess_lsars** Docker containers.

### train ###
This container is responsible for training the [PRIMERA model](https://github.com/allenai/PRIMER) on the [LSARS dataset](https://github.com/ScarletPan/LSARS). 

The inputs to this container are the following:
- 5,000 preprocessed and translated LSARS data points which we generated for Milestone 2, each of which contains:   
    - A unique identifier   
    - 10-40 product reviews   
    - One summary review which captures information from all of the reviews
- Training parameters
- Secrets file (contains service account credentials for Google Cloud)

The output of this container is a file (`pytorch_model.bin`) containing trained model weights. The weight file for each training run is automatically uploaded to Weights and Biases (WandB) at the end of the run.

This container holds the following files:
1. `src/train/train.py` This script trains the PRIMERA model on the LSARS dataset. The script provides options for data augmentation, data streaming, and data downloading from our GCP bucket, as well as standard training parameters such as learning rate and batch size. WandB tracking is integrated into the script, including model upload to WandB at the end of a training run. In our initial runs shown in this milestone, we use pre-trained weights from a version of PRIMERA trained on the [Multi-News dataset](https://huggingface.co/datasets/multi_news). This allows us to leverage transfer learning. In later training runs, we will experiment with using pre-trained weights for only some layers of the model. The PRIMERA model is [hosted](https://huggingface.co/allenai/PRIMERA/tree/main) on Huggingface.
2. `src/train/Dockerfile` This docker sets up a `pipenv` virtual environment for model training. In the file, we use our service account to connect to Google Cloud. We then create a user named `app` and install the required python packages from `src/preprocess_google/Pipfile`. Key packages used in model training include [Pytorch](https://pytorch.org/), [Transformers](https://huggingface.co/docs/transformers/index), and [NLTK](https://www.nltk.org/).
3. `src/train/docker-shell.sh` This script sets up a network so the Docker container can communicate with the outside world via ports. Next, the script builds our Docker container and uses `src/train/docker-compose.yml` to set up the full container environment. In `src/train/docker-compose.yml`, we specify GPU capabilities so the Docker container can take advantage of running on a VM with a GPU.

We ran this container inside a GCP VM with a Nvidia L4 GPU. Due to the large model size, an L4 GPU with 24GB of GPU RAM is required for training. We provide detailed instructions for VM setup and model training in the [Setup Notes](https://github.com/hpiercehoffman/AC215_FlavorFusion/edit/milestone3/README.md#setup-notes) section below.

### docker-volumes ###
This directory is mounted to the `train` Docker container in `src/train/docker-compose.yml`. The `docker-volumes/training-data` directory appears inside the Docker container as `/app/data`. Users may specify this directory as a data download and/or model output directory via parameters to the `train.py` script. This permits the Docker container to access the filesystem of the host VM, allowing downloaded data files and model result files to be saved on the VM even after the Docker container is no longe running.

### notebooks ###    
This directory is currently empty, but will be used to store code which doesn't belong to a specific container, such as reports, insights, or visualizations.

### reports ###
This directory contains our reports from past milestones:
- [Milestone 2](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone2.md): Data preprocessing, Label Studio, and DVC.

### References ###  
(add info here)

--------
# Setup Notes #

### Running Docker containers ###   
Both Docker containers delivered in this milestone can be run via the `docker-shell.sh` script inside the container. To run the container of your choice, do the following:
- Clone the repository and checkout the `milestone2` branch
- `cd src/<desired_directory>`
- `chmod 777 docker-shell.sh`
- `./docker-shell.sh`
The relevant Dockerfile will build and you will be dropped into a shell prompt as `app` user. From there, you can run a data processing script or connect to a Jupyter session. 

### Running preprocess_lsars.py script ###
To run this script, you must activate the `preprocess_lsars` docker container. Once you are inside the container, you can run the script with the following arguments:
- `-d` or `--download`: Flag to indicate that the untranslated data should be downloaded from our GCS bucket (will not overwrite any previously translated data)
- `--reviews_file_path`: Path to untranslated review file (either pre-mounted or downloaded with the `-d` flag)
- `--start_line`: Line in the input file where translation should start (each line is a single JSON record containing a summary and a group of reviews)
- `--stop_line`: Line in the input file where translation should stop
- `--output_file_path`: Path where translated data will be placed (should be in a mounted volume to avoid losing the data)
- `--upload`: Flag to indicate whether the output file should be uploaded to our GCS bucket 
   
Since the LSARS dataset contains large files, we provide `start_line` and `stop_line` arguments so the user can avoid reading an entire file into memory at once. We also provide the option of downloading the raw data, which is useful if the user is working in a GCP VM without a mounted bucket.     
    
Translating 500 reviews takes about 6 minutes. The script will output a progress bar showing how many records have been translated.



### Committing data files to DVC ###
We use DVC as our data versioning pipeline. Our DVC configuration has one remote for each dataset. The remote for LSARS data is called `lsars-data`, and the remote for Google data is called `google-data`. 

To download a specific version of one of our datasets, you can use the [dvc get](https://dvc.org/doc/command-reference/get) command. You need to specify a [dataset tag](https://github.com/hpiercehoffman/AC215_FlavorFusion/tags) as well as a remote to use.

**Example of downloading a specific dataset version**   
`dvc get https://github.com/hpiercehoffman/AC215_FlavorFusion/ src/docker-volumes/lsars-data --force --rev  lsars_train500 --remote lsars-data`     
  
The above command will download the `lsars-data` directory from the `lsars-data` remote. The data version will match the `lsars_train500` tag.

To add new or modified data files to DVC, you can use the [dvc add](https://dvc.org/doc/command-reference/add) command. You can then use [dvc push](https://dvc.org/doc/command-reference/push) to push to the appropriate remote.   
  
**Example of pushing new data to DVC**    
`dvc add src/docker-volumes/lsars-data`  
`dvc push src/docker-volumes/lsars-data -r lsars-data`  
  
The above commands will add any modifications in the `lsars-data` directory to the DVC staging area, then push these modifications to the DVC remote which handles LSARS data.

# References #

1. Xiao, Wen, Iz Beltagy, Giuseppe Carenini, and Arman Cohan. “PRIMERA: Pyramid-Based Masked Sentence Pre-Training for Multi-Document Summarization.” arXiv, March 16, 2022. http://arxiv.org/abs/2110.08499.
2. Yan, An, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. “Personalized Showcases: Generating Multi-Modal Explanations for Recommendations.” arXiv, April 6, 2023. http://arxiv.org/abs/2207.00422.
3. Pan, Haojie, Rongqin Yang, Xin Zhou, Rui Wang, Deng Cai, and Xiaozhong Liu. “Large Scale Abstractive Multi-Review Summarization (LSARS) via Aspect Alignment.” In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2337–46. Virtual Event China: ACM, 2020. https://doi.org/10.1145/3397271.3401439.
4. Text generated by ChatGPT, OpenAI, March 7, 2023, https://chat.openai.com/chat.



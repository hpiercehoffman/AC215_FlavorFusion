AC215: Milestone 4
==============================

Project Organization
------------
      ├── LICENSE
      ├── README.md
      ├── notebooks
      ├── references
      │   └── references.md
      ├── reports
      │   ├── milestone2.md
      │   └── milestone3.md
      ├── requirements.txt
      └── src
            ├── docker-volumes
            │   ├── google-data.dvc
            │   ├── lsars-data.dvc
            │   └── notebooks
            │       ├── process_google.ipynb
            │       ├── process_lsars.ipynb
            │       └── Evaluation_Example.ipynb
            ├── preprocess_google
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess.py
            │   ├── cors.py
            │   ├── utils.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh	
            ├── preprocess_lsars
            │   ├── Dockerfile
            │   ├── Pipfile
            │   ├── Pipfile.lock
            │   ├── preprocess_lsars.py
            │   ├── docker-compose.yml
            │   └── docker-shell.sh
            └── train
                ├── Dockerfile
                ├── Pipfile
                ├── Pipfile.lock
                ├── train_serverless.py
                ├── config.yml
                ├── requirements.txt
                └── submit_job.sh

--------
# Milestone 4 Overview

**Team Members**   
Varun Ullanat, Hannah Pierce-Hoffman

**Group Name**   
FlavorFusion

**Project**   
In this project, we aim to build an app that captures cultural differences in Google resturaunt reviews using abstractive summaries generated by a large language model.

For a full list of external references used in this project, please refer to our [reference document](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/references/references.md).

## Milestone 4 Deliverables ##

This milestone deals with model optimization and deployment.
- For information on data preprocessing, see our [Milestone 2 report](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone2.md). Data preprocessing takes place in the **preprocess_google** and **preprocess_lsars** Docker containers.
- For information on model training, see our [Milestone 3 report](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone3.md). Model training takes place in the **train** Docker container.

### Model Optimization ###

We implemented two model optimizations: **quantization** and **pruning**. 
- Quantization optimizes a trained model by storing model weights at a lower precision. We wanted to use quantization to try to reduce the model size and speed up model inference.
- Pruning optimizes a trained model by removing weights which are close to zero. Similar to quantization, we wanted to use pruning to reduce the model size and speed up model inference. Pruning can also reduce overfitting in some cases, which would help our model generalize to new inputs during inference.

We use Intel's [Neural Compressor library](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html) to implement both quantization and pruning. Neural Compressor offers a Huggingface integration called [Optimum Intel](https://github.com/huggingface/optimum-intel) which integrates with other Huggingface model optimization tools.

Optimum Intel performs quantization and pruning as a post-training step, using a similar interface to the Huggingface Trainer class. Therefore, we added quantization and pruning flags to our existing training script. By changing the command line arguments to the training script, it's possible to run either optimization or quantization on a previously trained model. See the [Setup Notes](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone4/README.md#setup-notes) section for full details of how to run these optimization methods.

### Model Deployment: Cloud Functions ###

We deploy multiple models as [Cloud Functions](https://cloud.google.com/functions?hl=en). 
- (List item 1)
- (List item 2)

The below screenshots show our cloud function deployments in action. We can modulate the input to a cloud function by editing the URL to the endpoint. For more details on setting up and running cloud functions, see the [Setup Notes](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone4/README.md#setup-notes) section below.

(Include screenshots)

### notebooks ###    
This directory is currently empty, but will be used to store code which doesn't belong to a specific container, such as reports, insights, or visualizations. 

### reports ###
This directory contains our reports from past milestones:
- [Milestone 2](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone2.md): Data preprocessing, Label Studio, and DVC.
- [Milestone 3](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/reports/milestone3.md): Model training, VM setup, and experiment tracking. 

### references ###  
This directory contains information on models, datasets, and other external references used in this project. References are detailed in [references.md](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/references/references.md).

--------
# Setup Notes #

### Using Artifact Registry ###


### Serverless Training ###  


### Running Quantization and Pruning ###


### Cloud Function Setup ###


# References #

For a full list of external references used in this project, please refer to our [reference document](https://github.com/hpiercehoffman/AC215_FlavorFusion/blob/milestone3/references/references.md).



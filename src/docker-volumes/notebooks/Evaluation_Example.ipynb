{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36735b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    LEDForConditionalGeneration,\n",
    ")\n",
    "from transformers import LEDConfig\n",
    "import sys\n",
    "sys.path.append('/n/data1/hms/dbmi/zitnik/lab/users/vau974/apcomp/PRIMER/script')\n",
    "from datasets import load_dataset, load_metric\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2258dbeb-afad-4885-a0a2-6f89448de270",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTS = np.array(['American restaurant', 'Angler fish restaurant',\n",
    "       'Armenian restaurant', 'Asian fusion restaurant',\n",
    "       'Asian restaurant', 'Australian restaurant', 'Austrian restaurant',\n",
    "       'Barbecue restaurant', 'Breakfast restaurant', 'Brunch restaurant',\n",
    "       'Buffet restaurant', 'Burrito restaurant',\n",
    "       'Cheesesteak restaurant', 'Chicken restaurant',\n",
    "       'Chicken wings restaurant', 'Chinese noodle restaurant',\n",
    "       'Chinese restaurant', 'Chophouse restaurant',\n",
    "       'Continental restaurant', 'Delivery Chinese restaurant',\n",
    "       'Delivery Restaurant', 'Dessert restaurant',\n",
    "       'Down home cooking restaurant', 'European restaurant',\n",
    "       'Family restaurant', 'Fast food restaurant', 'Filipino restaurant',\n",
    "       'Fine dining restaurant', 'Fish & chips restaurant',\n",
    "       'German restaurant', 'Gluten-free restaurant', 'Greek restaurant',\n",
    "       'Hamburger restaurant', 'Hawaiian restaurant',\n",
    "       'Health food restaurant', 'Hoagie restaurant',\n",
    "       'Hot dog restaurant', 'Indian restaurant', 'Irish restaurant',\n",
    "       'Israeli restaurant', 'Italian restaurant', 'Japanese restaurant',\n",
    "       'Korean restaurant', 'Latin American restaurant',\n",
    "       'Lebanese restaurant', 'Lunch restaurant', 'Meat dish restaurant',\n",
    "       'Mediterranean restaurant', 'Mexican restaurant',\n",
    "       'Mexican torta restaurant', 'Middle Eastern restaurant',\n",
    "       'Mongolian barbecue restaurant', 'New American restaurant',\n",
    "       'Organic restaurant', 'Pan-Asian restaurant',\n",
    "       'Peruvian restaurant', 'Pho restaurant', 'Pizza restaurant',\n",
    "       'Ramen restaurant', 'Restaurant', 'Restaurant or cafe',\n",
    "       'Restaurant supply store', 'Rice restaurant', 'Seafood restaurant',\n",
    "       'Small plates restaurant', 'Soul food restaurant',\n",
    "       'Soup restaurant', 'Southeast Asian restaurant',\n",
    "       'Southern restaurant (US)', 'Southwestern restaurant (US)',\n",
    "       'Spanish restaurant', 'Sushi restaurant', 'Taco restaurant',\n",
    "       'Taiwanese restaurant', 'Takeout Restaurant', 'Takeout restaurant',\n",
    "       'Tex-Mex restaurant', 'Thai restaurant',\n",
    "       'Traditional American restaurant', 'Traditional restaurant',\n",
    "       'Vegan restaurant', 'Vegetarian restaurant',\n",
    "       'Venezuelan restaurant', 'Vietnamese restaurant',\n",
    "       'Western restaurant'], dtype='<U31')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f59338",
   "metadata": {},
   "source": [
    "First, we load the **Multi-news** dataset from huggingface dataset hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faeeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset('multi_news')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9137321",
   "metadata": {},
   "source": [
    "Then we load the fine-tuned PRIMERA model, please download [it](https://storage.googleapis.com/primer_summ/PRIMER_multinews.tar.gz) to your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890f434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('allenai/PRIMERA')\n",
    "\n",
    "config=LEDConfig.from_pretrained('allenai/PRIMERA')\n",
    "\n",
    "MODEL = LEDForConditionalGeneration.from_pretrained('allenai/PRIMERA').to(device)\n",
    "\n",
    "MODEL.gradient_checkpointing_enable()\n",
    "PAD_TOKEN_ID = TOKENIZER.pad_token_id\n",
    "DOCSEP_TOKEN_ID = TOKENIZER.convert_tokens_to_ids(\"<doc-sep>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3341cac-cec3-4c3b-a36c-e2b7ac3b192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = open(path, 'r')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def make_metadata_df(fl):\n",
    "    parser = parse(fl)\n",
    "    rest_records = []\n",
    "    for record in parser:\n",
    "        if record['category'] != None:\n",
    "            if not set(record['category']).isdisjoint(RESTS):\n",
    "                rest_records.append([record['name'],\n",
    "                                     record['gmap_id'],\n",
    "                                     record['address'],\n",
    "                                     record['avg_rating'],\n",
    "                                     record['relative_results'],\n",
    "                                     record['num_of_reviews']])\n",
    "    \n",
    "    df = pd.DataFrame(rest_records, columns=['Name', 'gmap_id', 'address', 'avg_rating', \n",
    "                                             'relative_results', 'num_of_reviews'])\n",
    "    return df\n",
    "\n",
    "def make_reviews_df(fl, min_char=0, max_char=10000):\n",
    "    parser = parse(fl)\n",
    "    reviews = []\n",
    "    for review in parser:\n",
    "        if review['text'] != None:\n",
    "            if len(review['text']) >= min_char and len(review['text']) < max_char:\n",
    "                reviews.append([review['name'],\n",
    "                                review['rating'],\n",
    "                                review['text'],\n",
    "                                review['gmap_id']\n",
    "                               ])\n",
    "    df = pd.DataFrame(reviews, columns=['name', 'rating', 'text', 'gmap_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0963d6d-f941-467e-a2bd-9513d8f69260",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = make_reviews_df('review-Wyoming_10.json')\n",
    "meta_df = make_metadata_df('meta-Wyoming.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e63505d-099b-4885-8761-88f715c22a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df[meta_df['num_of_reviews'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bfe494-5be5-4bb6-a2a2-ff55365cb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = reviews_df.merge(meta_df, on=\"gmap_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f88ec3-67c5-447f-8987-11c6ec5a2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = combined_df.loc[:,['text', 'Name']]\n",
    "sub_df = sub_df.groupby([\"Name\"]).agg({\"text\": \"|||||\".join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc383d5-5d7f-4103-b540-88b19e1ae596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225 BBQ etc</td>\n",
       "      <td>Delicious BBQ in the heart of Star Valley. We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4th on Main</td>\n",
       "      <td>Nice venue. Good  food. Could have better serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 Bytes Game Cafe</td>\n",
       "      <td>Was extremely impressed all around with this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 Iron Italian Grill</td>\n",
       "      <td>The food was hot and fresh. Tasted great!  Our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A&amp;W Restaurant</td>\n",
       "      <td>I decided to give A&amp;W another chance yesterday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Windy Peaks Brewery &amp; Steakhouse</td>\n",
       "      <td>Good beer , friendly staff and good food.  Had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Wing Street</td>\n",
       "      <td>Service was slow. Order got mixed up. Manager ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Wy Thai</td>\n",
       "      <td>We drove up on impulse to get some dinner, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Wycolo Lodge</td>\n",
       "      <td>Very excellent experience!  Clean restaurant. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Wylie’s Canteen at Lake Lodge</td>\n",
       "      <td>I had a small plate veggie lasagna and let me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name  \\\n",
       "0                         225 BBQ etc   \n",
       "1                         4th on Main   \n",
       "2                   8 Bytes Game Cafe   \n",
       "3                9 Iron Italian Grill   \n",
       "4                      A&W Restaurant   \n",
       "..                                ...   \n",
       "229  Windy Peaks Brewery & Steakhouse   \n",
       "230                       Wing Street   \n",
       "231                           Wy Thai   \n",
       "232                      Wycolo Lodge   \n",
       "233     Wylie’s Canteen at Lake Lodge   \n",
       "\n",
       "                                                  text  \n",
       "0    Delicious BBQ in the heart of Star Valley. We ...  \n",
       "1    Nice venue. Good  food. Could have better serv...  \n",
       "2    Was extremely impressed all around with this p...  \n",
       "3    The food was hot and fresh. Tasted great!  Our...  \n",
       "4    I decided to give A&W another chance yesterday...  \n",
       "..                                                 ...  \n",
       "229  Good beer , friendly staff and good food.  Had...  \n",
       "230  Service was slow. Order got mixed up. Manager ...  \n",
       "231  We drove up on impulse to get some dinner, but...  \n",
       "232  Very excellent experience!  Clean restaurant. ...  \n",
       "233  I had a small plate veggie lasagna and let me ...  \n",
       "\n",
       "[234 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5da325e2-faae-455d-a42a-7a7a076ca02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_review(documents):\n",
    "    input_ids_all=[]\n",
    "    for data in documents:\n",
    "        all_docs = data.split(\"|||||\")[:-1]\n",
    "        for i, doc in enumerate(all_docs):\n",
    "            doc = doc.replace(\"\\n\", \" \")\n",
    "            doc = \" \".join(doc.split())\n",
    "            all_docs[i] = doc\n",
    "\n",
    "        #### concat with global attention on doc-sep\n",
    "        input_ids = []\n",
    "        for doc in all_docs:\n",
    "            input_ids.extend(\n",
    "                TOKENIZER.encode(\n",
    "                    doc,\n",
    "                    truncation=True,\n",
    "                    max_length=4096 // len(all_docs),\n",
    "                )[1:-1]\n",
    "            )\n",
    "            input_ids.append(DOCSEP_TOKEN_ID)\n",
    "        input_ids = (\n",
    "            [TOKENIZER.bos_token_id]\n",
    "            + input_ids\n",
    "            + [TOKENIZER.eos_token_id]\n",
    "        )\n",
    "        input_ids_all.append(torch.tensor(input_ids))\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids_all, batch_first=True, padding_value=PAD_TOKEN_ID\n",
    "    )\n",
    "    return input_ids\n",
    "\n",
    "def batch_process_review(batch):\n",
    "    input_ids=process_document_review(batch).to(device)\n",
    "    # get the input ids and attention masks together\n",
    "    global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
    "    # put global attention on <s> token\n",
    "\n",
    "    global_attention_mask[:, 0] = 1\n",
    "    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
    "    generated_ids = MODEL.generate(\n",
    "        input_ids=input_ids,\n",
    "        global_attention_mask=global_attention_mask,\n",
    "        use_cache=True,\n",
    "        max_length=2048,\n",
    "        num_beams=5,\n",
    "    )\n",
    "    generated_str = TOKENIZER.batch_decode(\n",
    "            generated_ids.tolist(), skip_special_tokens=True\n",
    "        )\n",
    "    result={}\n",
    "    result['generated_summaries'] = generated_str\n",
    "    #result['gt_summaries']=batch['summary']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7fddb90-9595-4482-855e-6ee92678ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:46<00:00,  4.62s/it]\n"
     ]
    }
   ],
   "source": [
    "reviews = sub_df['text'].values\n",
    "batch_size = 1\n",
    "end = 10\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch_start in tqdm(range(0,end,batch_size)):\n",
    "    batch = reviews[batch_start:batch_start+batch_size]\n",
    "    result = batch_process_review(batch)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fc2af0b-904c-4dad-a8ef-727a5d393af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delicious BBQ in the heart of Star Valley. We are huge fans of the brisket, we get it every time. We also love their smoked mac and cheese, and their bbq sauces are all amazing, we don\\'t have one favorite, there\\'s just too many good ones to choose from. Highly recommend this place. 👍|||||Absolutely the best BBQ in town. Get there early enough to get the Smoked Mac and cheese. It\\'s to die for.\\nThe owners have created an amazing business and the food is even better.\\nPrices, sizes, and taste will not disappoint.|||||Small portions for price. Chicken thigh and maybe 6 oz of chopped brisket with 2 sides for $15! All the brisket I\\'ve eaten in Texas is sliced and they offer lean or moist. The coleslaw was bland and the smoked macaroni and cheese was okay.|||||Bought brisket and pulled pork. Did not want sandwich or meat and 2 or 3 asked for # of each with sides. Here overnight with NO plates or flatware. Asked for this and was told \" not the way we usually do things\" grudgingly gave us 3 plates.\\nBrisket dry tasteless and needed seasoning. Pulled pork slightly better. Whit BBQ sauce did not help and we wondered why regular BBQ sauce not offered. Disappointed as we were tired and hungry.|||||Very good BBQ, eat in or take out. Street parking. Selection of pork, beef, ribs, sausage and specials. Sides are excellent and generous in size. Closes early so plan ahead. Excellent value.|||||Great food at a really good price. The smoked Mac N Cheese is really good and I don\\'t think you could go wrong with any of the meats. We especially liked the chicken. Service was super friendly!|||||Really great BBQ. Just what you\\'d hope for in a small town pit. Try it all.|||||Got half rack of rib no smoke ring taste like they were cooked in oven very disappointed|||||Enjoyed my ribs.  Thanks for supper!!|||||Really....?|||||Awesome|||||Absolutely delicious!!!!!!'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd99c767-6e7b-414d-99c3-f4853c40982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_summaries': [\"Delicious BBQ in the heart of Star Valley.We are huge fans of the brisket, we get it every time. We also love their smoked mac and cheese, and their bbq sauces are all amazing, we don't have one favorite, there's just too many good ones to choose from. Highly recommend this place. 👍Absolutely the best BBQ in town. Get there early enough to get the Smoked Mac and cheese..\"]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5153d-8c86-4a0d-a893-9579dcd9f499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5aabfc",
   "metadata": {},
   "source": [
    "We then define the functions to pre-process the data, as well as the function to generate summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bfecd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(documents):\n",
    "    input_ids_all=[]\n",
    "    for data in documents:\n",
    "        all_docs = data.split(\"|||||\")[:-1]\n",
    "        for i, doc in enumerate(all_docs):\n",
    "            doc = doc.replace(\"\\n\", \" \")\n",
    "            doc = \" \".join(doc.split())\n",
    "            all_docs[i] = doc\n",
    "\n",
    "        #### concat with global attention on doc-sep\n",
    "        input_ids = []\n",
    "        for doc in all_docs:\n",
    "            input_ids.extend(\n",
    "                TOKENIZER.encode(\n",
    "                    doc,\n",
    "                    truncation=True,\n",
    "                    max_length=4096 // len(all_docs),\n",
    "                )[1:-1]\n",
    "            )\n",
    "            input_ids.append(DOCSEP_TOKEN_ID)\n",
    "        input_ids = (\n",
    "            [TOKENIZER.bos_token_id]\n",
    "            + input_ids\n",
    "            + [TOKENIZER.eos_token_id]\n",
    "        )\n",
    "        input_ids_all.append(torch.tensor(input_ids))\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids_all, batch_first=True, padding_value=PAD_TOKEN_ID\n",
    "    )\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def batch_process(batch):\n",
    "    input_ids=process_document(batch['document']).to(device)\n",
    "    print(input_ids.shape)\n",
    "    # get the input ids and attention masks together\n",
    "    global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
    "    # put global attention on <s> token\n",
    "\n",
    "    global_attention_mask[:, 0] = 1\n",
    "    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
    "    generated_ids = MODEL.generate(\n",
    "        input_ids=input_ids,\n",
    "        global_attention_mask=global_attention_mask,\n",
    "        use_cache=True,\n",
    "        max_length=1024,\n",
    "        num_beams=5,\n",
    "    )\n",
    "    generated_str = TOKENIZER.batch_decode(\n",
    "            generated_ids.tolist(), skip_special_tokens=True\n",
    "        )\n",
    "    result={}\n",
    "    result['generated_summaries'] = generated_str\n",
    "    result['gt_summaries']=batch['summary']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f3053",
   "metadata": {},
   "source": [
    "Next, we simply run the model on 10 data examples (or any number of examples you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "631ead96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 658])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  20%|██        | 2/10 [00:04<00:18,  2.30s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 721])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  40%|████      | 4/10 [00:10<00:15,  2.59s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2318])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  60%|██████    | 6/10 [00:18<00:13,  3.30s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  80%|████████  | 8/10 [00:26<00:07,  3.54s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3207])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:44<00:00,  4.48s/ examples]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_idx = random.choices(range(len(dataset['test'])),k=10)\n",
    "dataset_small = dataset['test'].select(data_idx)\n",
    "result_small = dataset_small.map(batch_process, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a67e0f8-01b5-4212-8ce8-0faeccbb1292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'– She wasn\\'t a Target employee, but a woman who sure seemed like one allegedly made off with around $40,000 worth of iPhones from a Virginia store. NBC Washington reports Fairfax County cops are looking for the retail impostor, who they say donned attire resembling a worker\\'s getup, waltzed into the stockroom of the Alexandria location with a box, and loaded the box with dozens of iPhones before taking off. WTOP reports the woman, whose image was caught on tape, seemed to be familiar with how things worked at the store, including employee hours and where the iPhones were stored. Police say the theft occurred March 15, but posted about it on Facebook Monday with a call to \"help us nab an iPhone thief.\" (Target recently had a Boston problem.)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_small[2]['gt_summaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2aa63b4a-a20a-4ce2-a2c1-1d0b0777325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Fairfax County police are searching for a woman suspected of impersonating a Target employee and stealing more than $40,000 worth of iPhones. See video. \\n \\n WASHINGTON — Fairfax County police are searching for a woman suspected of impersonating a Target employee and stealing more than $40,000 worth of iPhones earlier this month. \\n \\n Police released surveillance footage Tuesday of the suspect leaving the store. \\n \\n On March 15, an unidentified woman impersonated a Target employee at the 6600 Richmond Highway location in Alexandria, Virginia, police said. \\n \\n She gained access to the stockroom and from there, police said she took the iPhones and put them in a box before leaving the store. \\n \\n Surveillance footage shows the woman leaving the store and getting into a Volvo station wagon. \\n \\n The suspect was familiar with store procedures, employee hours and where iPhones were kept in the stockroom. \\n \\n Anyone with more information about this case can call Fairfax County police at 703-691-2131. \\n \\n Watch the video below. \\n \\n Like WTOP on Facebook and follow @WTOP on Twitter to engage in conversation about this article and others. \\n \\n © 2017 WTOP. All Rights Reserved. ||||| Detectives in Virginia are looking for a woman who disguised herself as a Target employee and stole more than $40,000 worth of iPhones. \\n \\n The woman, dressed as an employee of Target, walked into the Richmond Highway store and made her way back to the stockroom. Once inside, she placed the iPhones in a box and left the store, Fairfax County police said. \\n \\n Surveillance cameras were able to capture pictures of the woman. \\n \\n Detectives said the woman is not affiliated with the store but appeared to know the store's procedures and location of the iPhones in the stockroom.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_small[2]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96ad01a5-fb23-4c29-b233-7a8f7db1bd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON — Fairfax County police are searching for a woman suspected of impersonating a Target employee and stealing more than $40,000 worth of iPhones earlier this month. Police released surveillance footage Tuesday of the suspect leaving the store..'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_small[2]['generated_summaries']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dd96d",
   "metadata": {},
   "source": [
    "After getting all the results, we load the evaluation metric. \n",
    "\n",
    "\n",
    "(Note in the original code, we didn't use the default aggregators, instead, we simply take average over all the scores.\n",
    "We simply use 'mid' in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f31905",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81814601",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_small['generated_summaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9923d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=rouge.compute(predictions=result_small[\"generated_summaries\"], references=result_small[\"gt_summaries\"])\n",
    "print(score['rouge1'].mid)\n",
    "print(score['rouge2'].mid)\n",
    "print(score['rougeL'].mid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
